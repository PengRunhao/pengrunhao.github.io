<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>VisionTransformer | 睡觉大王的博客</title><meta name="author" content="Peng Runhao"><meta name="copyright" content="Peng Runhao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="VisionTransformer1.Transformer Encoder Block 上图是transformer encoder block的详细结构图，下面根据此图来搭建Transformer encoder block。 1.1 DropPath模块DropPath使网络在训练时以一定的概率丢弃主路径的输出，在推理时不丢弃。迫使网络依赖残差连接或者其他路径的输出，从而增强模型的鲁棒性和泛">
<meta property="og:type" content="article">
<meta property="og:title" content="VisionTransformer">
<meta property="og:url" content="http://pengrunhao.github.io/2025/05/09/VisionTransformer/index.html">
<meta property="og:site_name" content="睡觉大王的博客">
<meta property="og:description" content="VisionTransformer1.Transformer Encoder Block 上图是transformer encoder block的详细结构图，下面根据此图来搭建Transformer encoder block。 1.1 DropPath模块DropPath使网络在训练时以一定的概率丢弃主路径的输出，在推理时不丢弃。迫使网络依赖残差连接或者其他路径的输出，从而增强模型的鲁棒性和泛">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://pengrunhao.github.io/img/cat.jpg">
<meta property="article:published_time" content="2025-05-09T06:57:00.000Z">
<meta property="article:modified_time" content="2025-05-13T02:53:49.062Z">
<meta property="article:author" content="Peng Runhao">
<meta property="article:tag" content="博客, 睡觉大王">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://pengrunhao.github.io/img/cat.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://pengrunhao.github.io/2025/05/09/VisionTransformer/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Peng Runhao","link":"链接: ","source":"来源: 睡觉大王的博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'VisionTransformer',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-05-13 10:53:49'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/cat.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">40</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/moon.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="睡觉大王的博客"><span class="site-name">睡觉大王的博客</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">VisionTransformer</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-05-09T06:57:00.000Z" title="发表于 2025-05-09 14:57:00">2025-05-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-13T02:53:49.062Z" title="更新于 2025-05-13 10:53:49">2025-05-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ML-DL/">ML&amp;DL</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="VisionTransformer"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="VisionTransformer"><a href="#VisionTransformer" class="headerlink" title="VisionTransformer"></a>VisionTransformer</h1><h2 id="1-Transformer-Encoder-Block"><a href="#1-Transformer-Encoder-Block" class="headerlink" title="1.Transformer Encoder Block"></a>1.Transformer Encoder Block</h2><p><img src="/2025/05/09/VisionTransformer/transformer_encoder.png" alt></p>
<p>上图是transformer encoder block的详细结构图，下面根据此图来搭建Transformer encoder block。</p>
<h3 id="1-1-DropPath模块"><a href="#1-1-DropPath模块" class="headerlink" title="1.1 DropPath模块"></a>1.1 DropPath模块</h3><p><code>DropPath</code>使网络在训练时以一定的概率丢弃主路径的输出，在推理时不丢弃。迫使网络依赖残差连接或者其他路径的输出，从而增强模型的鲁棒性和泛化能力。与Dropout不同，Dropout是随机丢弃某个神经元，而<code>DropPath</code>是随机丢弃整个路径。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">drop_path</span>(<span class="params">x, drop_prob: <span class="built_in">float</span> = <span class="number">0.</span>, training: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">if</span> drop_prob == <span class="number">0.</span> <span class="keyword">or</span> <span class="keyword">not</span> training:   <span class="comment">#当丢弃率为0或者不是训练阶段时，返回x本身</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    keep_prob = <span class="number">1</span> - drop_prob</span><br><span class="line">    shape = (x.shape[<span class="number">0</span>],) + (<span class="number">1</span>,)*(x.ndim - <span class="number">1</span>)  <span class="comment">#创建一个与x尺寸相同的掩码，保留Batch维度，其余维度都填1，例如若 x 是 [batch, channels, height, width]（4D），则 shape = (batch, 1, 1, 1)。生成的掩码可以广播到x的所有维度。</span></span><br><span class="line">    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)  <span class="comment">#生成一个形状为shape的随机张量,值为[keep_prob, 1+keep_prob)</span></span><br><span class="line">	random_tensor.floor_() <span class="comment">#对random_tensor进行向下取整操作，将其二值化为0或1。如果值在[keep_prob,1)，取整后为0(丢弃路径)，如果在[1, 1+keep_prob),取整后为1(保留路径)。因为torch.rand是均匀分布，所以值为0的概率是drop_porb，值为1的概率是keep_prob</span></span><br><span class="line">    output = x.div(keep_prob) * random_tensor <span class="comment">#x/keep_prob,对x的数值进行放大，补偿路径丢弃带来的幅度减少。再*randon_tensor，逐元素相乘，遇0丢弃，遇1保留。使用广播机制。</span></span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DropPath</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, drop_prob=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(DropPath, self).__init__()</span><br><span class="line">        self.drop_prob = drop_prob</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> drop_path(x, self.drop_prob, self.training)</span><br></pre></td></tr></table></figure>
<h3 id="1-2-Patch-Embedding模块"><a href="#1-2-Patch-Embedding模块" class="headerlink" title="1.2 Patch Embedding模块"></a>1.2 Patch Embedding模块</h3><p>Patch Embedding模块主要通过一个卷积操作来将图像数据转换为一个个向量，以[224, 224, 3]的输入图像为例，若patch_size=16，则经过768个kernel_size=16, stride=14的卷积核进行卷积操作，输出维度就会变为[14, 14, 768]。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PatchEmbed</span>(nn.Module):  <span class="comment"># 2D Image to Patch Embedding</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_c=<span class="number">3</span>, embed_dim=<span class="number">768</span>, norm_layer=<span class="literal">None</span></span>):</span><br><span class="line">        supe().__init__()</span><br><span class="line">        img_size = (img_size, img_size)</span><br><span class="line">        patch_size = (patch_size, patch_size)</span><br><span class="line">        self.img_size = img_size</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        self.grid_size = (img_size[<span class="number">0</span>] // patch_size[<span class="number">0</span>], img_size[<span class="number">1</span>] // patch_size[<span class="number">1</span>])   <span class="comment"># (224//16, 224//16) = (14, 14)</span></span><br><span class="line">        self.num_patches = self.gird_size[<span class="number">0</span>] * self.grid_size[<span class="number">1</span>]  <span class="comment">#14*14=196</span></span><br><span class="line">        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size) <span class="comment">#定义输入3通道，输出768通道的大小为16*16，步长为16的卷积操作，[3,224,224]的图像经过该卷积操作变为[768,14,14]</span></span><br><span class="line">        self.norm = norm_layer(embed_dim) <span class="keyword">if</span> norm_layer <span class="keyword">else</span> nn.Identity()   <span class="comment">#如果没有指明norm_layer就不进行任何操作</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        B, C, H, W = x.shape</span><br><span class="line">        <span class="keyword">assert</span> H == self.img_size[<span class="number">0</span>] <span class="keyword">and</span> W == self.img_size[<span class="number">1</span>], \</span><br><span class="line">        	<span class="string">f&quot;Input image size (<span class="subst">&#123;H&#125;</span>*<span class="subst">&#123;W&#125;</span>) doesn&#x27;t match model (<span class="subst">&#123;self.img_size[<span class="number">0</span>]&#125;</span>*<span class="subst">&#123;self.img_size[<span class="number">1</span>]&#125;</span>).&quot;</span></span><br><span class="line">        x = self.proj(x).flatten(<span class="number">2</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>在forward中，<code>self.proj(x):</code>[Batch, 3, 224, 224] —&gt; [Batch, 768, 14, 14]，<code>flatten:</code> [B, C, H, W] -&gt; [B, C, HW] 即 [Batch, 768, 196]，<code>transpose:</code> [B, C, HW] -&gt; [B, HW, C] 即 [Batch, 196, 768]。</p>
<h3 id="1-3-Attention-模块"><a href="#1-3-Attention-模块" class="headerlink" title="1.3 Attention 模块"></a>1.3 Attention 模块</h3><p>多头注意力机制主要通过线性层self.qkv将输入的dim维向量映射到dim*3维，然后根据头数进行reshape，之后交换位置，拆分出各自的q，k，v。通过矩阵乘法@计算Q@K，然后乘以缩放因子，进行softmax来计算注意力权重，用注意力权重对V加权求和，然后将每个head对应的结果拼接，得到原始维度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                dim,             <span class="comment"># 输入token的维度</span></span></span><br><span class="line"><span class="params">                num_heads=<span class="number">8</span>,     <span class="comment"># 多头注意力的头数，默认为8</span></span></span><br><span class="line"><span class="params">                qkv_bias=<span class="literal">False</span>,  <span class="comment"># 是否在计算Q，K，V的线性变换为加入偏置，默认为False。</span></span></span><br><span class="line"><span class="params">                qk_scale=<span class="literal">None</span>,   <span class="comment"># 注意力分数的缩放因子</span></span></span><br><span class="line"><span class="params">                attn_drop_ratio=<span class="number">0.</span>,   <span class="comment"># 注意力分数的dropout比例，默认为0</span></span></span><br><span class="line"><span class="params">                proj_drop_ratio=<span class="number">0.</span></span>):  <span class="comment"># 最后投影层的dropout比例，默认为0</span></span><br><span class="line">        <span class="built_in">super</span>(Attention, self).__init__()</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        head_dim = dim // num_heads   <span class="comment"># 每一个head的维度 = 总维度 / head的个数</span></span><br><span class="line">        self.scale = qk_scale <span class="keyword">or</span> head_dim ** -<span class="number">0.5</span>  <span class="comment">#缩放因子，用于缩放QK的结果，防止数值过大导致softmax梯度消失</span></span><br><span class="line">        self.qkv = nn.Linear(dim, dim*<span class="number">3</span>, bias=qkv_bias)  <span class="comment">#一个线形层，将输入的dim维向量映射到dim*3维，用于生成Q，K，V向量</span></span><br><span class="line">        self.attn_drop = nn.Dropout(attn_drop_ratio)</span><br><span class="line">        self.proj = nn.Linear(dim, dim)  <span class="comment"># 最后的线性投影层，将多头注意力的输出映射回dim维。</span></span><br><span class="line">        self.proj_drop = nn.Dropout(proj_drop_ratio)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># [batch_size, num_patches + 1, total_embed_dim(每个token的嵌入维度，即dim)]</span></span><br><span class="line">        B, N, C = x.shape</span><br><span class="line">        qkv = self.qkv(x).reshape(B, N, <span class="number">3</span>, self.num_heads, C // self.num_heads).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>) <span class="comment">#[3, batch_size, num_heads, num_patches + 1, embed_dim_per_head]</span></span><br><span class="line">        q, k, v = qkv[<span class="number">0</span>], qkv[<span class="number">1</span>], qkv[<span class="number">2</span>]  <span class="comment">#[batch_size, num_heads, num_patches + 1, embed_dim_per_head]</span></span><br><span class="line">        attn = (q@k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) * self.scale  <span class="comment">#用每个heads的qkv进行操作，这里只会对最后两个维度进行矩阵乘法</span></span><br><span class="line">        attn = attn.softmax(dim=-<span class="number">1</span>)   <span class="comment"># 对每一行的数据进行softmax</span></span><br><span class="line">        attn = self.attn_drop(attn)</span><br><span class="line">        x = (attn @ v).transpose(<span class="number">1</span>, <span class="number">2</span>).reshape(B, N, C) <span class="comment">#[batch_size, num_patches + 1, total_embed_dim],将每个head对应位置的结果拼接在一起</span></span><br><span class="line">        x = self.proj(x)</span><br><span class="line">        x = self.proj_drop(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="1-4-MLP-模块"><a href="#1-4-MLP-模块" class="headerlink" title="1.4 MLP 模块"></a>1.4 MLP 模块</h3><p>MLP位于多头注意力机制之后，MLP模块与多头注意力机制模块共同构成一个transformer block，多头注意力机制主要负责捕捉token之间的全局依赖关系，而MLP主要对每个token的特征进行独立的高维非线性变换，通过扩展到更高维度的隐藏层，一般是输出维度的4倍，使模型能学习到更复杂的特征，来增强模型的表达能力。</p>
<p>MLP主要包括两层全连接网络，和激活函数以及Dropout层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_features, hidden_features=<span class="literal">None</span>, out_features=<span class="literal">None</span>, act_layer=nn.GELU, drop=<span class="number">0.</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__();</span><br><span class="line">        out_features = out_features <span class="keyword">or</span> in_features</span><br><span class="line">        hidden_features = hidden_features <span class="keyword">or</span> in_features</span><br><span class="line">        self.fc1 = nn.Linear(in_features, hidden_features)</span><br><span class="line">        self.act = act_layer()</span><br><span class="line">        self.fc2 = nn.Linear(hidden_features, out_features)</span><br><span class="line">        self.drop = nn.Dropout(drop)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.drop(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="1-5-Block"><a href="#1-5-Block" class="headerlink" title="1.5 Block"></a>1.5 Block</h3><p>将多头注意力机制，DropPath，MLP等组合起来，就构成了一个Transformer Encoder Block。代码完全按照上图结构编写。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                dim,</span></span><br><span class="line"><span class="params">                num_heads,</span></span><br><span class="line"><span class="params">                mlp_ratio=<span class="number">4.</span>,</span></span><br><span class="line"><span class="params">                qkv_bias=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                qk_scale=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                drop_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                attn_drop_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                drop_path_ratio=<span class="number">0.</span>,</span></span><br><span class="line"><span class="params">                act_layer=nn.GELU,</span></span><br><span class="line"><span class="params">                norm_layer=nn.LayerNorm</span>):</span><br><span class="line">        <span class="built_in">super</span>(Block, self).__init__()</span><br><span class="line">        self.norm1 = norm_layer(dim)</span><br><span class="line">        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, </span><br><span class="line">                              attn_drop_ratio=attn_drop_ratio, proj_drop_ratio=drop_ratio)</span><br><span class="line">        self.drop_path = DropPath(drop_path_ratio) <span class="keyword">if</span> drop_path_ratio &gt; <span class="number">0.</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        self.norm2 = norm_layer(dim)</span><br><span class="line">        mlp_hidden_dim = <span class="built_in">int</span>(dim * mlp_ratio)</span><br><span class="line">        self.mlp = MLP(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop_ratio)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x + self.drop_path(self.attn(self.norm1(x)))</span><br><span class="line">        x = x + self.drop_path(self.mlp(self.norm2(x)))</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="2-ViT"><a href="#2-ViT" class="headerlink" title="2.ViT"></a>2.ViT</h2><p><img src="/2025/05/09/VisionTransformer/ViT_B_16.png" alt></p>
<p>Vision-Transformer根据patch的大小，Block的堆叠数量，Hidden_size的大小，多头的数量分为好几个版本。下面只记录Vision-Transformer的网络架构，以及最基础的<code>ViT-B/16</code>模型</p>
<h3 id="2-1-Vision-Transformer网络架构"><a href="#2-1-Vision-Transformer网络架构" class="headerlink" title="2.1 Vision-Transformer网络架构"></a>2.1 Vision-Transformer网络架构</h3><p>网络结构严格按照上图，结构清晰。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VisionTransformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_c=<span class="number">3</span>, num_classes=<span class="number">1000</span>, embed_dim=<span class="number">768</span>, depth=<span class="number">12</span>,</span></span><br><span class="line"><span class="params">                 num_heads=<span class="number">12</span>, mlp_ratio=<span class="number">4.0</span>, qkv_bias=<span class="literal">True</span>, qk_scale=<span class="literal">None</span>, representation_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 distilled=<span class="literal">False</span>, drop_ratio=<span class="number">0.</span>, attn_drop_ratio=<span class="number">0.</span>, drop_path_ratio=<span class="number">0.</span>,                                  embed_layer=PatchEmbed, norm_layer=<span class="literal">None</span>, act_layer=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        num_classes: 分类任务的类别数</span></span><br><span class="line"><span class="string">        embed_dim: embedding dimension</span></span><br><span class="line"><span class="string">        depth: transformer block堆叠的个数</span></span><br><span class="line"><span class="string">        representation_size:  enable and set representation layer (pre-logits) to this value if set</span></span><br><span class="line"><span class="string">        distilled: 用于DeiT模型，此处不考虑</span></span><br><span class="line"><span class="string">        embed_layer: patch embedding layer</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(VisionTransformer, self).__init__()</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.num_features = self.embed_dim = embed_dim</span><br><span class="line">        self.num_tokens = <span class="number">2</span> <span class="keyword">if</span> distilled <span class="keyword">else</span> <span class="number">1</span>  <span class="comment"># 此处不考虑DeiT，num_tokens = 1</span></span><br><span class="line">        norm_layer = norm_layer <span class="keyword">or</span> partial(nn.LayerNorm, eps=<span class="number">1e-6</span>)</span><br><span class="line">        act_layer = act_layer <span class="keyword">or</span> nn.GELU</span><br><span class="line">        </span><br><span class="line">        self.patch_embed = embed_layer(img_size=img_size, patch_size=patch_size, in_c=in_c, embed_dim=embed_dim)</span><br><span class="line">        num_patches = self.patch_embed.num_patches  <span class="comment">#num_patches是根据PatchEmbed类中的参数计算得出的</span></span><br><span class="line">        </span><br><span class="line">        self.cls_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim))  <span class="comment">#第一个1是batch维度，方便计算。这里可以看到class token的实现方式是创建一个可学习的尺寸是[1, 1, 768]的全零张量。nn.Parameter()可以确保张量被nn.Module识别为模型参数，参与梯度计算和优化器更新。</span></span><br><span class="line">        self.dist_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim)) <span class="keyword">if</span> distilled <span class="keyword">else</span> <span class="literal">None</span>  <span class="comment"># 无关</span></span><br><span class="line">        self.pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches+self.num_tokens, embed_dim))  <span class="comment"># 位置编码的实现与cls同理，只是由于cls的加入，位置编码的第二维度+1</span></span><br><span class="line">        self.pos_drop = nn.Dropout(p=drop_ratio)  <span class="comment"># 根据网络结构图，在position embedding之后有一层dropout</span></span><br><span class="line">        </span><br><span class="line">        dpr = [x.item() <span class="keyword">for</span> x <span class="keyword">in</span> torch.linspace(<span class="number">0</span>, drop_path_ratio, depth)]  <span class="comment">#生成一个递增的drop_path_ration序列，最小是0.，最大是drop_path_ratio</span></span><br><span class="line">        self.blocks = nn.Sequential(*[</span><br><span class="line">            Block(dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias,                             qk_scale=qk_scale, drop_ratio=drop_ratio, attn_drop_ratio=attn_drop_ratio,                               drop_path_ratio=dpr[i], norm_layer=norm_layer, act_layer=act_layer)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)</span><br><span class="line">        ])</span><br><span class="line">        <span class="comment"># * 是解包运算符，用于将列表推导式生成的Block模块列表解包,将[Block1, Block2, ...]转换为Block1, Block2, ...，从而正确初始化 nn.Sequential 容器。</span></span><br><span class="line">        self.norm = norm_layer(embed_dim)</span><br><span class="line">        </span><br><span class="line">        self.has_logits = <span class="literal">False</span></span><br><span class="line">        self.pre_logits = nn.Identity()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Classifier heads 分类头</span></span><br><span class="line">        self.head = nn.Linear(self.num_features, num_classes) <span class="keyword">if</span> num_classes &gt; <span class="number">0</span> <span class="keyword">else</span> nn.Identity()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Weight init</span></span><br><span class="line">        nn.init.trunc_normal_(self.pos_embed, std=<span class="number">0.02</span>)</span><br><span class="line">        nn.init.trunc_normal_(self.cls_token, std=<span class="number">0.02</span>)</span><br><span class="line">        self.apply(_init_vit_weights)   <span class="comment"># apply是nn.Module内置的方法，该类已继承nn.Module，故无需声明。</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_features</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.patch_embed(x)  <span class="comment"># [B, C, H, W] -&gt; [B, num_patches, embed_dim] ([B, 196, 768])</span></span><br><span class="line">        cls_token = self.cls_token.expand(x.shape[<span class="number">0</span>], -<span class="number">1</span>, -<span class="number">1</span>) <span class="comment">#将cls_token在batch维度复制batch_size份</span></span><br><span class="line"></span><br><span class="line">        x = torch.cat((cls_token, x), dim=<span class="number">1</span>) <span class="comment">#[B, 197, 768] 在第二个维度上将class token与x进行拼接</span></span><br><span class="line">        </span><br><span class="line">        x = self.pos_drop(x + self.pos_embed)   <span class="comment">#给x加上位置编码，然后进行dropout</span></span><br><span class="line">        x = self.blocks(x)   </span><br><span class="line">        x = self.norm(x)</span><br><span class="line">        <span class="keyword">return</span> self.pre_logits(x[:, <span class="number">0</span>])  <span class="comment">#这里pre_logits是nn.Identity(),第一个维度是batch，取所有batch，第二个0表示取每个batch的第一个向量，即class token</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.forward_features(x)</span><br><span class="line">        x = self.head(x)  <span class="comment"># self.head就是最后的Linear全连接层</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h3 id="2-2-Vision-Transformer权重初始化"><a href="#2-2-Vision-Transformer权重初始化" class="headerlink" title="2.2 Vision-Transformer权重初始化"></a>2.2 Vision-Transformer权重初始化</h3><p>函数<code>isinstance()</code>用于检查不同的模块类型（<code>nn.Linear</code>, <code>nn.Conv2d</code>, <code>nn.LayerNorm</code>），根据不同的模块类型，选择不同的初始化策略。</p>
<p><code>nn.init.trunc_normal_(m.weights, std=0.01)</code>，截断正态分布，从正态分布中采样，但值限制在一定的范围之内，通常是正负2倍的std，这种初始化方式在Transformer中常见，有利于稳定早期的训练梯度。</p>
<p> <code>nn.init.kaiming_normal_(m.weight, mode=&quot;fan_out&quot;)</code>，Kaiming初始化，主要为卷积网络设计，通过调整权重方差来保持梯度稳定性，基于正态分布，<code>mode=&quot;fan_out&quot;</code>表示根据输出特征数量计算方差。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_init_vit_weights</span>(<span class="params">m</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Linear):</span><br><span class="line">        nn.init.trunc_normal_(m.weight, std=<span class="number">0.01</span>)</span><br><span class="line">        <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.zeros_(m.bias)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.Conv2d):</span><br><span class="line">        nn.init.kaiming_normal_(m.weight, mode=<span class="string">&quot;fan_out&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn.init.zeros_(m.bias)</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(m, nn.LayerNorm):</span><br><span class="line">        nn.init.zeros_(m.bias)</span><br><span class="line">        nn.init.ones_(m.weight)</span><br></pre></td></tr></table></figure>
<h3 id="2-3-ViT-B-16"><a href="#2-3-ViT-B-16" class="headerlink" title="2.3 ViT_B/16"></a>2.3 ViT_B/16</h3><p><img src="/2025/05/09/VisionTransformer/ViT类别.png" alt></p>
<p>设计好ViT的网络结构和初始化方法之后，只需要传入不同的参数就可以实例化不同的网络。ViT的常见网络有上图三种。这里只实例化ViT_B/16，其余类似。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">vit_base_patch16_224</span>(<span class="params">num_classes: <span class="built_in">int</span> = <span class="number">1000</span></span>):</span><br><span class="line">    </span><br><span class="line">    model = VisionTransformer(img_size=<span class="number">224</span>,</span><br><span class="line">                              patch_size=<span class="number">16</span>,</span><br><span class="line">                              embed_dim=<span class="number">768</span>,</span><br><span class="line">                              depth=<span class="number">12</span>,</span><br><span class="line">                              num_heads=<span class="number">12</span>,</span><br><span class="line">                              representation_size=<span class="literal">None</span>,</span><br><span class="line">                              num_classes=num_classes)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h2 id="3-Dataset"><a href="#3-Dataset" class="headerlink" title="3.Dataset"></a>3.Dataset</h2><p>模型搭建完毕之后，要能在自己的数据集上跑，还需要重写Dataset，由于数据的组织方式不同，模型与数据之间如何适配于我而言是个问题，通过本文希望可以加强自己这方面的能力。</p>
<p><code>__getitem__()</code>魔法方法，当通过索引访问数据集对象，或者通过dataloader迭代时，会自动调用该方法。</p>
<p><code>collate_fn()</code>将一个batch的数据进行整理和格式化，以便后续输入到网络模型中。接收的参数<code>batch</code>是一个列表，包含多个数据样本，每个样本通常是<code>__getitem__()</code>方法返回的，例如<code>batch=[(image1, label1), (image2, label2), (image3, label3)]</code>, 则<code>*batch=(image1, label1), (image2, label2), (image3, label3)</code>，zip的作用是将batch中所有元组的对应元素分组，<code>zip(*batch) = zip((image1, label1), (image2, label2), (image3, label3)) = [(image1, image2, image3), (label1, label2, label3)]</code>，可以看到经过zip后，数据进行了分组，但类型又变为了列表，故最后再用<code>tuple()</code>函数将其变为元组类型，<code>tuple(zip(*batch)) = ((image1, image2, image3), (label1, label2, label3))</code>，将其分别赋值给images，labels。然后将image数据在第一个维度上折叠，使多个<code>[C, H, W]</code>变为<code>[B, C, H, W]</code>，再对labels进行转tensor操作，就可以将其直接输入网络模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, images_path: <span class="built_in">list</span>, images_class: <span class="built_in">list</span>, transform=<span class="literal">None</span></span>):</span><br><span class="line">        self.images_path = images_path</span><br><span class="line">        self.images_class = images_class</span><br><span class="line">        self.transform = transform</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):   <span class="comment"># 返回数据集的总样本数</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images_path)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):  <span class="comment">#通过索引item获取数据样本，通常是一个元组，包含输入数据和标签</span></span><br><span class="line">        img = Image.<span class="built_in">open</span>(self.images_path[img])</span><br><span class="line">        <span class="comment"># RGB为彩图，L为灰度图</span></span><br><span class="line">        <span class="keyword">if</span> img.mode != <span class="string">&#x27;RGB&#x27;</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;image: &#123;&#125; isn&#x27;t RGB mode.&quot;</span>.<span class="built_in">format</span>(self.images_path[item]))</span><br><span class="line">        label = self.images_class[item]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            img = self.transform(img)</span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod  </span><span class="comment">#静态方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch</span>):  <span class="comment">#静态方法属于类，而不是类的实例，故调用时不需要传递self参数</span></span><br><span class="line">        images, labels = <span class="built_in">tuple</span>(<span class="built_in">zip</span>(*batch))  <span class="comment">#见上文</span></span><br><span class="line">        </span><br><span class="line">        images = torch.stack(images, dim=<span class="number">0</span>) <span class="comment">#将img元组在第一个维度上折叠，即两个2个[3,224,224]变为[2,3,224,224]</span></span><br><span class="line">        labels = torch.as_tensor(labels)  <span class="comment">#将标签元组转变为张量</span></span><br><span class="line">        <span class="keyword">return</span> images, labels</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://pengrunhao.github.io">Peng Runhao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://pengrunhao.github.io/2025/05/09/VisionTransformer/">http://pengrunhao.github.io/2025/05/09/VisionTransformer/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://pengrunhao.github.io" target="_blank">睡觉大王的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/cat.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2025/04/16/Leetcode206-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/" title="Leetcode206.反转链表"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Leetcode206.反转链表</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/cat.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Peng Runhao</div><div class="author-info__description">千里之行，始于足下。</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">40</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#VisionTransformer"><span class="toc-number">1.</span> <span class="toc-text">VisionTransformer</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Transformer-Encoder-Block"><span class="toc-number">1.1.</span> <span class="toc-text">1.Transformer Encoder Block</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-DropPath%E6%A8%A1%E5%9D%97"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 DropPath模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-Patch-Embedding%E6%A8%A1%E5%9D%97"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 Patch Embedding模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-Attention-%E6%A8%A1%E5%9D%97"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.3 Attention 模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-MLP-%E6%A8%A1%E5%9D%97"><span class="toc-number">1.1.4.</span> <span class="toc-text">1.4 MLP 模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-5-Block"><span class="toc-number">1.1.5.</span> <span class="toc-text">1.5 Block</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-ViT"><span class="toc-number">1.2.</span> <span class="toc-text">2.ViT</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-Vision-Transformer%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 Vision-Transformer网络架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Vision-Transformer%E6%9D%83%E9%87%8D%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 Vision-Transformer权重初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-ViT-B-16"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 ViT_B&#x2F;16</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Dataset"><span class="toc-number">1.3.</span> <span class="toc-text">3.Dataset</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/09/VisionTransformer/" title="VisionTransformer">VisionTransformer</a><time datetime="2025-05-09T06:57:00.000Z" title="发表于 2025-05-09 14:57:00">2025-05-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/16/Leetcode206-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/" title="Leetcode206.反转链表">Leetcode206.反转链表</a><time datetime="2025-04-16T06:56:13.000Z" title="发表于 2025-04-16 14:56:13">2025-04-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/16/Leetcode146-LRU%E7%BC%93%E5%AD%98/" title="Leetcode146.LRU缓存">Leetcode146.LRU缓存</a><time datetime="2025-04-15T16:22:23.000Z" title="发表于 2025-04-16 00:22:23">2025-04-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/14/%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" title="交叉熵损失函数">交叉熵损失函数</a><time datetime="2025-04-14T14:24:14.000Z" title="发表于 2025-04-14 22:24:14">2025-04-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/12/Leetcode3-%E6%97%A0%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%90%E4%B8%B2/" title="Leetcode3.无重复字符的最长子串">Leetcode3.无重复字符的最长子串</a><time datetime="2025-04-11T17:57:11.000Z" title="发表于 2025-04-12 01:57:11">2025-04-12</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Peng Runhao</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>